{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HtIKd8KN2XiY",
        "MoBLDTKI2fXW",
        "Lnc9YmU42hUR",
        "BeJTWqyH3J1B",
        "06OiPswx3B9v",
        "q8cLwTlP3lBa",
        "s5T5dbViUxHq",
        "Ov7Ghjen3gXP",
        "q_mk4LRmLhSd",
        "te9PXAfXUDY8",
        "rDpB-qzUYCaB",
        "5BxOG5rlYg-P",
        "CvH6hhxzoWVx",
        "cvkG2n0d8mSM",
        "PXs9rkn08veU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 01_Library"
      ],
      "metadata": {
        "id": "HtIKd8KN2XiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install"
      ],
      "metadata": {
        "id": "MoBLDTKI2fXW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "PCFVyCEe2PVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5814269-ae51-4210-9985-3e8c196cab6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m799.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import torchtext\n",
        "except ImportError:\n",
        "    ! pip install -q torchtext==0.17.0\n",
        "    import torchtext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import"
      ],
      "metadata": {
        "id": "Lnc9YmU42hUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset#, random_split\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "id": "c1IQIhZI2lSk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------"
      ],
      "metadata": {
        "id": "Oe4RFU5r2nAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 02_Utils"
      ],
      "metadata": {
        "id": "vZcFxNTi2oOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## system"
      ],
      "metadata": {
        "id": "BeJTWqyH3J1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system= \"colab\"\n",
        "\n",
        "if system== \"local\":\n",
        "    project_path= r\"./\"\n",
        "    dataset_path= './wikitext-2/'\n",
        "\n",
        "elif system== \"colab\":\n",
        "    root_path= '/content/'\n",
        "    project_path= r\"/content/drive/MyDrive/Catalist/1_language modeling/\"\n",
        "    dataset_path= os.path.join(project_path, r'dataset/wikitext-2/')\n",
        "\n",
        "else:\n",
        "  raise ValueError(\"Invalid system\")\n"
      ],
      "metadata": {
        "id": "g9WyhGuE3Fpl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## device"
      ],
      "metadata": {
        "id": "06OiPswx3B9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "SLtfbFUe2nrb",
        "outputId": "4efeb888-bbd8-4125-9572-df55751ca987"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## drive mount"
      ],
      "metadata": {
        "id": "q8cLwTlP3lBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if system== \"colab\":\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-aLyPQ7I3nid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95a5118-12e5-4b6f-d51f-0bab3e1332ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## number of params fn"
      ],
      "metadata": {
        "id": "s5T5dbViUxHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def num_trainable_params(model):\n",
        "  nums= sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
        "  return nums"
      ],
      "metadata": {
        "id": "MkO-Zv1cUw0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------"
      ],
      "metadata": {
        "id": "gZDO-FBI3d8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03_Data"
      ],
      "metadata": {
        "id": "Ov7Ghjen3gXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WikiTextDataset:\n",
        "    def __init__(self, file_path):\n",
        "        self.file_path= file_path\n",
        "\n",
        "    def __iter__(self):\n",
        "        with open(self.file_path, 'r', encoding= 'utf-8') as f:\n",
        "            for line in f:\n",
        "                yield line.strip()\n",
        "\n",
        "train_iter= WikiTextDataset(os.path.join(dataset_path, \"wiki.train.tokens\"))\n",
        "valid_iter= WikiTextDataset(os.path.join(dataset_path, \"wiki.valid.tokens\"))\n",
        "test_iter= WikiTextDataset(os.path.join(dataset_path, \"wiki.test.tokens\"))\n",
        "\n",
        "train_iter_= iter(train_iter)\n",
        "print(next(train_iter_))\n",
        "print(next(train_iter_))"
      ],
      "metadata": {
        "id": "ETPirO6Gzmjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be305e23-1bc1-41bd-e35d-6a6e04e51144"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "= Valkyria Chronicles III =\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------"
      ],
      "metadata": {
        "id": "O32h15BVZI1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 04_Tokenize & Vocab"
      ],
      "metadata": {
        "id": "q_mk4LRmLhSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer= get_tokenizer('basic_english')\n",
        "vocab= build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "torch.save(vocab, 'vocab.pt')\n",
        "vocab(['amir', 'hi', 'rookie', 'fouladi'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHCDaYnFLHn1",
        "outputId": "ebc2a0f4-3ca2-4699-ef89-c0d767fa56cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 9206, 6358, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----"
      ],
      "metadata": {
        "id": "0sWtrAOYZKrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 05_EDA"
      ],
      "metadata": {
        "id": "te9PXAfXUDY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mean sentence length"
      ],
      "metadata": {
        "id": "rDpB-qzUYCaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_sentence_count= 0\n",
        "total_sentence_length= 0\n",
        "\n",
        "for line in train_iter:\n",
        "    sentences= line.split('.')\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens= sentence.strip().split()\n",
        "        sentence_length= len(tokens)\n",
        "\n",
        "        if sentence_length >0:\n",
        "            total_sentence_count +=1\n",
        "            total_sentence_length +=sentence_length\n",
        "\n",
        "mean_sentence_length= total_sentence_length/ total_sentence_count\n",
        "\n",
        "print(f'Mean sentence length in Wikitext-2: {mean_sentence_length:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa1scqHtUB0C",
        "outputId": "b8d863d1-df3e-459e-8d8b-85cf9b554778"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean sentence length in Wikitext-2: 21.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## most common and least common words"
      ],
      "metadata": {
        "id": "5BxOG5rlYg-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freqs= Counter()\n",
        "for tokens in map(tokenizer, train_iter):\n",
        "  freqs.update(tokens)"
      ],
      "metadata": {
        "id": "D141M3LKYfT4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqs.most_common()[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kMGqTQq_ZP5W",
        "outputId": "42a32cbb-4632-47be-89d1-7ce2b90cab72"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 130768),\n",
              " (',', 102615),\n",
              " ('.', 83397),\n",
              " ('of', 57030),\n",
              " ('<unk>', 54625),\n",
              " ('and', 50735),\n",
              " ('in', 45015),\n",
              " ('to', 39521),\n",
              " ('a', 36523),\n",
              " ('=', 29570),\n",
              " ('was', 21008),\n",
              " (\"'\", 18484),\n",
              " ('@-@', 16906),\n",
              " ('on', 15140),\n",
              " ('as', 15058),\n",
              " ('s', 14936),\n",
              " ('that', 14351),\n",
              " ('for', 13794),\n",
              " ('with', 13012),\n",
              " ('by', 12718)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqs.most_common()[-20:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u_2iH4btZQV_",
        "outputId": "ea357544-6cba-4ce1-cb44-1963bc50620e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('yellowwoods', 3),\n",
              " ('tomentum', 3),\n",
              " ('secretion', 3),\n",
              " ('spruces', 3),\n",
              " ('lewenthal', 3),\n",
              " ('caprices', 3),\n",
              " ('étude', 3),\n",
              " ('mineurs', 3),\n",
              " ('sonatine', 3),\n",
              " ('chants', 3),\n",
              " ('philipp', 3),\n",
              " ('prefaced', 3),\n",
              " ('kreutzer', 3),\n",
              " ('forrester', 3),\n",
              " ('zoromski', 3),\n",
              " ('roundabouts', 3),\n",
              " ('tuscola', 3),\n",
              " ('northeasterly', 3),\n",
              " ('intergrades', 3),\n",
              " ('gallinae', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------"
      ],
      "metadata": {
        "id": "C1HVbxUIZMV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 06_Preprocessing"
      ],
      "metadata": {
        "id": "CvH6hhxzoWVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_process(raw_text_iter, seq_len):\n",
        "  data= torch.cat([torch.LongTensor(vocab(tokenizer(line))) for line in raw_text_iter])\n",
        "  M, r= len(data) // seq_len, len(data) % seq_len\n",
        "  data= torch.cat((data, torch.LongTensor([0]))) if r==0 else data\n",
        "\n",
        "  inputs= data[:M* seq_len].reshape(-1, seq_len)\n",
        "  targets= data[1: M*seq_len +1].reshape(-1, seq_len)\n",
        "\n",
        "  return inputs, targets"
      ],
      "metadata": {
        "id": "I-tMEf99ZM6_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len= 35\n",
        "x_train, y_train= data_process(train_iter, seq_len)\n",
        "x_valid, y_valid= data_process(valid_iter, seq_len)\n",
        "x_test, y_test= data_process(test_iter, seq_len)\n",
        "\n",
        "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6xi-nQ-pUAo",
        "outputId": "38751344-bda9-47ca-f417-023d479b1871"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([58571, 35]),\n",
              " torch.Size([58571, 35]),\n",
              " torch.Size([6126, 35]),\n",
              " torch.Size([6126, 35]),\n",
              " torch.Size([6910, 35]),\n",
              " torch.Size([6910, 35]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------"
      ],
      "metadata": {
        "id": "tBxmZamf8q0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 07_Custom Dataset"
      ],
      "metadata": {
        "id": "cvkG2n0d8mSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, inputs, targets):\n",
        "    self.inputs= inputs\n",
        "    self.targets= targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.inputs.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.inputs[idx], self.targets[idx]"
      ],
      "metadata": {
        "id": "obgQq8r371I5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set= CustomDataset(x_train, y_train)\n",
        "valid_set= CustomDataset(x_valid, y_valid)\n",
        "test_set= CustomDataset(x_test, y_test)"
      ],
      "metadata": {
        "id": "oK8hRvjQ717_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------"
      ],
      "metadata": {
        "id": "VcoLcApb84tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 08_DataLoader"
      ],
      "metadata": {
        "id": "PXs9rkn08veU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size= 20\n",
        "train_loader= DataLoader(train_set, batch_size= batch_size, shuffle= True)\n",
        "valid_loader= DataLoader(valid_set, batch_size= 2*batch_size, shuffle= False)\n",
        "test_loader= DataLoader(test_set, batch_size= 2*batch_size, shuffle= False)"
      ],
      "metadata": {
        "id": "iWuf1Dw-8dTp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch= next(iter(train_loader))\n",
        "x_batch.shape, y_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qOLluwk9ETL",
        "outputId": "4cd2b6f3-178b-4df8-f0dd-c28e0bc1ce31"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([20, 35]), torch.Size([20, 35]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------"
      ],
      "metadata": {
        "id": "mlsX1XjLGnF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 09_Model"
      ],
      "metadata": {
        "id": "3cFcoJ6IGo6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers,\n",
        "                dropout_embd= 0.5, dropout_rnn= 0.5):\n",
        "    super().__init__()\n",
        "    self.num_layers= num_layers\n",
        "    self.hidden_dim= hidden_dim\n",
        "    self.embedding_dim= embedding_dim\n",
        "\n",
        "    self.embedding= nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
        "    self.dropout= nn.Dropout(p=dropout_embd)\n",
        "\n",
        "    self.lstm= nn.LSTM(embedding_dim, hidden_dim, num_layers= num_layers,\n",
        "                        dropout= dropout_rnn, batch_first= True)\n",
        "\n",
        "    self.fc= nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "  def forward(self, src):\n",
        "    embedding= self.dropout(self.embedding(src))\n",
        "    output, hidden= self.lstm(embedding)\n",
        "    prediction= self.fc(output)\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "kSZENAuDGnvL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= LanguageModel(vocab_size= len(vocab), embedding_dim= 300,\n",
        "                     hidden_dim= 512, num_layers= 2,\n",
        "                     dropout_embd= 0.65, dropout_rnn= 0.5)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFyJcS0ZIrss",
        "outputId": "af01e462-11b4-463b-f010-b840654639ee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 300)\n",
              "  (dropout): Dropout(p=0.65, inplace=False)\n",
              "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=512, out_features=28782, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_trainable_params(model))\n",
        "print(num_trainable_params(model.embedding))\n",
        "print(num_trainable_params(model.lstm))\n",
        "print(num_trainable_params(model.fc))"
      ],
      "metadata": {
        "id": "r2pZWIY7UpbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------"
      ],
      "metadata": {
        "id": "2jMtl3dHI-Ua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10_"
      ],
      "metadata": {
        "id": "3oU7tIYnJBcI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bsXdeK5pI-3W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}