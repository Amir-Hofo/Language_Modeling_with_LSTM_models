# Language Modeling with LSTM models

This project explores language modeling using LSTM-based architectures trained on the WikiText-2 dataset. Two models are implemented: a standard LSTM language model and an advanced AWD-LSTM variant with regularization techniques such as weight dropout and locked dropout. Given a text prompt, both models generate coherent sentence continuations.  
Example output:  
Prompt → "I'm not in danger, I am the"  
Model → "the best of any game."

![LM](https://github.com/user-attachments/assets/6654f230-5e4d-4b7e-92f0-475862bda4d4)
