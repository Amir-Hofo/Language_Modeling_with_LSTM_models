# Language Modeling with LSTM models

This project explores language modeling using LSTM-based architectures trained on the WikiText-2 dataset. Two models are implemented: a standard LSTM language model and an advanced AWD-LSTM variant with regularization techniques such as weight dropout and locked dropout. Given a text prompt, both models generate coherent sentence continuations.  
Example output:  
Prompt → "I'm not in danger, I am the"  
Model → "the best of any game."

![LM](https://github.com/user-attachments/assets/2dda6fac-cf45-486e-a2e5-4faf7f9deba7)
